{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata-based Specialization\n",
    "\n",
    "One previously employed method for estimating the degree of specialization in parliament is the use of politician co-occurrence counts. By calculating the number of times two politicians speak in the same session, one can construct a \"co-specialization\" index, as Otjes and Louwerse show. In this notebook, I calculate co-specialization over time, based on co-occurrence counts. I use PMI to score the co-occurrences.\n",
    "\n",
    "The PMI-scores are used to aggregate several signals:\n",
    "\n",
    "- the mean co-specialization\n",
    "- the variation in co-specialization\n",
    "- the concentration of co-specialization (as measured in entropy)\n",
    "- the modularity of co-specialization networks (as measured in modularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import entropy\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from novelty.metrics import softmax\n",
    "from novelty.afa import adaptive_filter\n",
    "import networkx as nx\n",
    "import math \n",
    "from itertools import combinations\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "plt.rcParams['font.family'] = 'Aptos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Metadata\n",
    "metadata = pd.read_csv('/home/rb/Documents/Data/metadata/metadata-full.tsv',sep='\\t',parse_dates=['date'])\n",
    "metadata = metadata[metadata.session_type == 'plenary']\n",
    "metadata['py'] = metadata.speech_id.str.split('.').str[4].str[:8]\n",
    "metadata['sess'] = metadata.speech_id.str.split('.').str[4:6].agg('.'.join)\n",
    "\n",
    "names = dict(zip(metadata['member-ref'],metadata.speaker))\n",
    "parties = dict(zip(metadata['member-ref'],metadata['party-ref']))\n",
    "\n",
    "# Date Dictionaries\n",
    "dates_topic = dict(zip(metadata.speech_id.str.split('.').str[4:6].str.join('.'), metadata.date))\n",
    "dates_speech = dict(zip(metadata.speech_id, metadata.date))\n",
    "\n",
    "# Change dates to 6-month bins, select only MPs, Plenaries, and remove joint House meetings\n",
    "\n",
    "metadata['date'] = metadata.date.apply(lambda d: pd.Timestamp(year = d.year, month=1 if d.month < 7 else 6, day=1))\n",
    "subset = metadata[(metadata.role == 'mp') & (metadata.py.str[4:6] == '19') & (metadata.date.dt.year > 1945)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over periods and members. Calculate PMI between member-member pairs based on co-occurrence in session\n",
    "\n",
    "r = []\n",
    "\n",
    "for pyg in tqdm([[f\"{i}{i+1}\",f\"{i+1}{i+2}\"] for i in range(1945,1993)]):\n",
    "    t = subset[subset.py.isin(pyg)]\n",
    "    t = t[t['member-ref'].map(t['member-ref'].value_counts()) > 10]\n",
    "    total_sessions = t.sess.nunique()\n",
    "\n",
    "    for member1, session_dat1 in t.groupby('member-ref'):\n",
    "        for member2, session_dat2 in t.groupby('member-ref'):\n",
    "            if member1 != member2:\n",
    "                f1 = session_dat1.sess.nunique()\n",
    "                f2 = session_dat2.sess.nunique()\n",
    "                f12 = len(set(session_dat1.sess.unique()).intersection(set(session_dat2.sess.unique())))\n",
    "                if f12 > 5:\n",
    "                    pmi = np.log2((f12 / total_sessions) / ((f1 / total_sessions) * (f2 / total_sessions)))\n",
    "                    r.append({'member1':member1, 'member2':member2,'pmi': pmi,'py':pyg[0], 'totsess':total_sessions,'f12':f12, 'f1':f1, 'f2':f2})\n",
    "                else:\n",
    "                    r.append({'member1':member1, 'member2':member2,'pmi': -100,'py':pyg[1], 'totsess':total_sessions,'f12':f12, 'f1':f1, 'f2':f2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = pd.DataFrame(r)\n",
    "\n",
    "# Select only positive scores\n",
    "rdn = rd[rd.pmi > -100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the PMI-values, aggregate different signals\n",
    "\n",
    "signals = pd.DataFrame({\"py\":sorted(rdn.py.unique())})\n",
    "\n",
    "## Mean\n",
    "signals = pd.merge(signals,rdn.groupby('py').pmi.mean().reset_index(name='mean_'), on='py')\n",
    "\n",
    "\n",
    "## Variation\n",
    "signals = pd.merge(signals,rdn.groupby('py').pmi.var().reset_index(name='variation'), on='py')\n",
    "\n",
    "## Concentration\n",
    "signals = pd.merge(signals,rdn.groupby('py').apply(lambda t:entropy(softmax(t.pmi))).reset_index(name='entropy'), on='py')\n",
    "\n",
    "## Modularity\n",
    "def get_mod(df):\n",
    "    # df = df.groupby('member1').apply(lambda g: g.nlargest(10,'pmi'))\n",
    "    G = nx.from_pandas_edgelist(df = df, source = 'member1', target = 'member2', edge_attr='pmi')\n",
    "    comms = nx.community.louvain_communities(G,weight='pmi')\n",
    "    return nx.community.quality.modularity(G,communities=comms)\n",
    "\n",
    "# Smooth Signals, Remove Prewar debates\n",
    "signals = pd.merge(signals,rdn[rdn.pmi > 0].groupby('py').apply(get_mod).reset_index(name='modularity'), on='py').set_index('py')\n",
    "# signals = signals[signals.py.dt.year > 1945].apply(zscore)\n",
    "# for c in signals.columns:\n",
    "#     signals[c] = adaptive_filter(signals[c],span=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "f,a = plt.subplots(2,2,figsize=(10,5),sharex=True)\n",
    "\n",
    "for cc,c in enumerate(signals):\n",
    "\n",
    "    ax = a.flatten()[cc]\n",
    "    ax.plot(signals.index,signals[c],alpha=.75)\n",
    "    ax.plot(signals.index,adaptive_filter(signals[c],span=10),alpha=.75)\n",
    "    ax.set_title(c.upper(),loc='left')\n",
    "    ax.xaxis.set_tick_params(rotation=90,size=5)\n",
    "\n",
    "    import matplotlib.ticker as plticker\n",
    "\n",
    "    loc = plticker.MultipleLocator(base=3) # this locator puts ticks at regular intervals\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "# plt.savefig('figs/metadata-spec-stats.png',dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = signals \n",
    "\n",
    "# Set up color palette for decades\n",
    "decades = df.index.str[:4].astype(int) // 10 * 10  # Group years into decades\n",
    "decade_palette = sns.color_palette(\"coolwarm\", n_colors=len(set(decades)))\n",
    "\n",
    "# Set up the plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Plot scatter points colored by decades\n",
    "# for i, (time, row) in enumerate(df.iterrows()):\n",
    "#     decade_index = list(set(decades)).index(decades[i])\n",
    "#     plt.scatter(row['entropy'], row['mean_'], color=decade_palette[decade_index])\n",
    "\n",
    "# Calculate centroid positions for each decade\n",
    "centroid_positions = {}\n",
    "for decade in set(decades):\n",
    "    points = df[df.index.str[:4].astype(int) // 10 * 10 == decade]\n",
    "    centroid_positions[decade] = (np.mean(points['entropy']), np.mean(points['mean_']))\n",
    "\n",
    "# Add annotation box for each decade\n",
    "for decade, position in centroid_positions.items():\n",
    "    color = decade_palette[list(set(decades)).index(decade)]\n",
    "    plt.annotate(f\"{decade}s\", position, fontsize=10, ha='center', va='center',\n",
    "                 bbox=dict(boxstyle=\"round\", facecolor=color, edgecolor='black'),\n",
    "                 color='black')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Entropy')\n",
    "plt.ylabel('Variation')\n",
    "\n",
    "# Show plot\n",
    "# plt.savefig('figs/quadrant-entropy-variance.png',dpi=400)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
